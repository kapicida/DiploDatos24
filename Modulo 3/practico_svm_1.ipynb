{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1VkI5oA8mtw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import svm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Zin2t4N-q4j"
      },
      "source": [
        "## Ejemplo 1 - Conjunto de datos separables linealmente\n",
        "\n",
        "Comenzaremos con un ejemplo de conjunto de datos en 2D que puede ser separado por un límite lineal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "4fgdv5i_AEoh",
        "outputId": "5db9ae29-cbbf-41f6-f280-ba48196cb838"
      },
      "outputs": [],
      "source": [
        "#Primero cargamos y graficamos los datos\n",
        "data = np.load(\"ex1_linear.npz\")\n",
        "\n",
        "X = data['X']\n",
        "y = data['y'][:,0]\n",
        "\n",
        "pos = y == 1\n",
        "neg = y == 0\n",
        "\n",
        "plt.plot(X[pos,0], X[pos,1], 'X', c='blue')\n",
        "plt.plot(X[neg,0], X[neg,1], 'o', c='red')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWwjzdBIUGcj"
      },
      "source": [
        "En general existen infinitas soluciones posibles para el problema de separar ambas clases:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "MV-OKeuQUUwh",
        "outputId": "3799c371-b5ac-4bcd-d2fe-662afe6627d0"
      },
      "outputs": [],
      "source": [
        "plt.plot(X[pos,0], X[pos,1], 'X', c='blue')\n",
        "plt.plot(X[neg,0], X[neg,1], 'o', c='red')\n",
        "xfit = np.linspace(0, 4)\n",
        "for w, b in [(-0.6, 4.5), (-0.7, 5.0), (-1, 5.6)]:\n",
        "  plt.plot(xfit, w * xfit + b, '-k')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "dxKWalLnv3kj",
        "outputId": "f394ea27-a901-4a18-d08d-7912206f5ac7"
      },
      "outputs": [],
      "source": [
        "#Según modelo de regresión logistica\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model_lr = LogisticRegression(random_state=0).fit(X, y)\n",
        "\n",
        "w_lr = model_lr.coef_[0]\n",
        "b_lr = model_lr.intercept_\n",
        "xp_lr = np.linspace(min(X[:, 0]), max(X[:, 0]), 100)\n",
        "yp_lr = -(w_lr[0] * xp_lr + b_lr)/w_lr[1]\n",
        "\n",
        "plt.plot(X[pos,0], X[pos,1], 'X', c='blue')\n",
        "plt.plot(X[neg,0], X[neg,1], 'o', c='red')\n",
        "plt.plot(xp_lr, yp_lr, '-k')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "Ny_3nzw4WdEV",
        "outputId": "4a52e549-fa43-44bb-f33d-30f5ffaf591c"
      },
      "outputs": [],
      "source": [
        "#Entrenamos un clasificador SVM utilizando un kernel lineal\n",
        "\n",
        "C = 1\n",
        "model = svm.SVC(random_state=0, kernel=\"linear\", C=C)\n",
        "model.fit(X, y)\n",
        "\n",
        "# Calculamos la función de decision\n",
        "w = model.coef_[0]\n",
        "b = model.intercept_\n",
        "xp = np.linspace(min(X[:, 0]), max(X[:, 0]), 100)\n",
        "yp = -(w[0] * xp + b)/w[1]\n",
        "\n",
        "# Graficamos la funcioń de decision\n",
        "plt.plot(X[pos,0], X[pos,1], 'X', c='blue')\n",
        "plt.plot(X[neg,0], X[neg,1], 'o', c='red')\n",
        "plt.plot(xp, yp, '-g', label='SVM')\n",
        "plt.plot(xp_lr, yp_lr, '-y', label='LR')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "ZpcUCbvQagRa",
        "outputId": "5fbacf3d-b531-4c1a-cc1d-0530e02ca715"
      },
      "outputs": [],
      "source": [
        "# Calculamos los vectores de soporte\n",
        "\n",
        "def plot_svc_decision_function(model, ax=None, plot_support=True):\n",
        "  \"\"\"Plot the decision function for a two-dimensional SVC\"\"\"\n",
        "  if ax is None:\n",
        "    ax = plt.gca()\n",
        "  xlim = ax.get_xlim()\n",
        "  ylim = ax.get_ylim()\n",
        "  # create grid to evaluate model\n",
        "  x = np.linspace(xlim[0], xlim[1], 30)\n",
        "  y = np.linspace(ylim[0], ylim[1], 30)\n",
        "  Y, X = np.meshgrid(y, x)\n",
        "  xy = np.vstack([X.ravel(), Y.ravel()]).T\n",
        "  P = model.decision_function(xy).reshape(X.shape)\n",
        "  # plot decision boundary and margins\n",
        "  ax.contour(X, Y, P, colors='k', levels=[-1, 0, 1], alpha=0.5, linestyles=['--', '-', '--'])\n",
        "  # plot support vectors\n",
        "  if plot_support:\n",
        "    ax.scatter(model.support_vectors_[:, 0], model.support_vectors_[:, 1], s=300, linewidth=2, alpha=.5);\n",
        "  ax.set_xlim(xlim)\n",
        "  ax.set_ylim(ylim)\n",
        "\n",
        "plt.plot(X[pos,0], X[pos,1], 'X', c='blue')\n",
        "plt.plot(X[neg,0], X[neg,1], 'o', c='red')\n",
        "plot_svc_decision_function(model);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myvacJm7YjY1"
      },
      "source": [
        "## Kernel trick"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "0Ko2OjTZdygB",
        "outputId": "4edb2f9f-c5e3-4f85-b0c8-c18135a8e126"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "\n",
        "# Generar un set de datos no lineal\n",
        "X, y = datasets.make_circles(n_samples=100, factor=0.6, noise=0.1)\n",
        "\n",
        "# Graficar los datos\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "jMtwooAEohm2",
        "outputId": "89d2942c-b212-49de-b266-e4a3a392a536"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "\n",
        "X, y = datasets.make_circles(n_samples=100, factor=0.6, noise=0.1)\n",
        "\n",
        "# Definir los parametros de la función gaussiana\n",
        "gamma = 0.5\n",
        "\n",
        "# Crear una grilla de puntos graficar la función gaussiana\n",
        "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.05),np.arange(y_min, y_max, 0.05))\n",
        "zz = np.exp(-(xx.ravel()**2 + yy.ravel()**2)/(2*gamma**2))\n",
        "\n",
        "\n",
        "# Compute the Gaussian function values\n",
        "Z = np.exp(-(X[:, 0].ravel()**2 + X[:, 1].ravel()**2)/(2*gamma**2))\n",
        "\n",
        "fig1 = px.scatter_3d(x=X[:, 0], y=X[:, 1], z=np.zeros(X.shape[0]), color=y)\n",
        "fig2 = px.scatter_3d(x=xx.ravel(), y=yy.ravel(), z=zz, opacity=0.1, color_discrete_sequence=[\"gray\"])\n",
        "\n",
        "fig1.add_traces(\n",
        "    list(fig2.select_traces()))\n",
        "\n",
        "# Show the figure\n",
        "fig1.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "7VI3il9DsLy_",
        "outputId": "e0facdb2-ae3d-487e-bea0-5d8289546ee8"
      },
      "outputs": [],
      "source": [
        "# Compute the Gaussian function values\n",
        "Z = np.exp(-(X[:, 0].ravel()**2 + X[:, 1].ravel()**2)/(2*gamma**2))\n",
        "\n",
        "fig1 = px.scatter_3d(x=X[:, 0], y=X[:, 1], z=Z, color=y)\n",
        "fig2 = px.scatter_3d(x=xx.ravel(), y=yy.ravel(), z=zz, opacity=0.1, color_discrete_sequence=[\"gray\"])\n",
        "\n",
        "fig1.add_traces(\n",
        "    list(fig2.select_traces()))\n",
        "\n",
        "# Show the figure\n",
        "fig1.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mh2FUztjxIVw"
      },
      "source": [
        "#### Separación Lineal en el Nuevo Espacio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "15jtxJWgwlYd",
        "outputId": "f04a2e6c-80fd-49ac-8917-f327c9709c7b"
      },
      "outputs": [],
      "source": [
        "# Agregamos una nueva característica a la matriz X, correspondiente a la nueva dimension\n",
        "newX = np.hstack((X,Z.reshape(-1,1)))\n",
        "\n",
        "# Entrenamos un modelo de SVM lineal en el nuevo espacio de caracteristicas\n",
        "svm_model_3d_linear = svm.SVC(kernel='linear', C=100)\n",
        "svm_model_3d_linear.fit(newX, y)\n",
        "\n",
        "# Coeficientes del plano de decisión\n",
        "coeficientes = svm_model_3d_linear.coef_\n",
        "intercepto = svm_model_3d_linear.intercept_\n",
        "\n",
        "# Calcular el valor z sobre plano de decisión\n",
        "z = (-coeficientes[:,0] * xx.ravel() - coeficientes[:,1] * yy.ravel() - intercepto) / coeficientes[:,2]\n",
        "\n",
        "# graficamos los datos\n",
        "fig1 = px.scatter_3d(x=X[:, 0], y=X[:, 1], z=Z, color=y, color_discrete_sequence={0:\"red\", 1:\"blue\"})\n",
        "\n",
        "# Crear una figura 2D (scatter plot) para visualizar el plano de decisión\n",
        "fig2 = px.scatter_3d(x=xx.ravel(), y=yy.ravel(), z=z)\n",
        "\n",
        "fig1.add_traces(\n",
        "    list(fig2.select_traces()))\n",
        "\n",
        "# Mostrar la figura\n",
        "fig1.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0Qg5pVk9RjN"
      },
      "source": [
        "### Volviendo al espacio original"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "k4asfx4hjITf",
        "outputId": "557cc0e0-a78a-4b17-d306-0a987c6e0eef"
      },
      "outputs": [],
      "source": [
        "# Entrenar un modelo de SVM con los mismos datos pero usando un kernel gaussiano o RBF\n",
        "svm_model = svm.SVC(kernel='rbf', C=1, gamma='scale')\n",
        "svm_model.fit(X, y)\n",
        "\n",
        "# Creamos  a mesh grid to plot the decision boundary\n",
        "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
        "                     np.arange(y_min, y_max, 0.01))\n",
        "\n",
        "# Plot the decision boundary\n",
        "Z = svm_model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "plt.contour(xx, yy, Z, alpha=0.5)\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
        "plt.title('SVM con kernel RBF')\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
