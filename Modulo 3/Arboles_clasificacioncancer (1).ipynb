{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUE5z6Gh5gUU"
      },
      "source": [
        "# Diplomatura en Ciencia de Datos - UNNE - 2024\n",
        "### Módulo 4: Aprendizaje Automático\n",
        "### Clase 2: Árboles de decisión"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYc3MPscVrnd"
      },
      "source": [
        "**Explicación de las Etiquetas en los Nodos del Árbol de Decisión:**\n",
        "\n",
        "Cuando visualizamos el árbol de decisión, podemos encontrar algunas etiquetas en los nodos que nos proporcionan información relevante sobre el proceso de clasificación:\n",
        "\n",
        "1. **Gini impurity (Gini):** Es una medida de la impureza de un nodo. Mientras más cerca esté de cero (0), más puro es el nodo y contiene principalmente ejemplos de una sola clase. Si Gini es cercano a uno (1), el nodo contiene una mezcla de diferentes clases.\n",
        "\n",
        "2. **Samples:** Indica el número total de ejemplos en el nodo que se están evaluando en ese paso del árbol.\n",
        "\n",
        "3. **Value:** Muestra la distribución de las clases en el nodo. En el primer ejemplo, tenemos dos clases \"Benigno\" y \"Malingno\", el valor [B, M] indicaría que hay \"B\" ejemplos de la clase \"Benigno\" y \"M\" ejemplos de la clase \"Malingno\" en ese nodo.\n",
        "\n",
        "4. **Class:** Cuando un nodo es puramente de una sola clase, se muestra el nombre de la clase. Por ejemplo, si el nodo contiene solo ejemplos de \"Malingno\", entonces la etiqueta sería \"M\".\n",
        "\n",
        "Es importante tener en cuenta que a medida que descendemos en el árbol, los nodos que están más cerca de la raíz son los que contienen características más generales y los que están más cerca de las hojas son los que contienen características más específicas para clasificar correctamente los ejemplos. El árbol de decisión utiliza estas etiquetas para tomar decisiones y clasificar nuevas imágenes según las características que encuentra en cada nodo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRqYNvcA38yR"
      },
      "source": [
        "## Dataset \"Breast Cancer Wisconsin (Diagnostic)\"\n",
        "Disponible en el repositorio de aprendizaje automático de la UCI (UCI Machine Learning Repository). Este conjunto de datos es ampliamente utilizado en la comunidad de aprendizaje automático y es un recurso común para la clasificación de cáncer de mama.\n",
        "\n",
        "El conjunto de datos contiene características calculadas a partir de imágenes digitalizadas de aspiraciones con aguja fina (FNA) de una masa mamaria. Estas características describen varios aspectos de los núcleos celulares presentes en las imágenes.\n",
        "\n",
        "A continuación, te proporciono una descripción general de las columnas presentes en el conjunto de datos:\n",
        "\n",
        "ID: Número de identificación del paciente.\n",
        "\n",
        "- Diagnóstico (Diagnosis): Variable objetivo que indica si la muestra es benigna (B) o maligna (M).\n",
        "\n",
        "10 características de valor real (real-valued features) que describen diferentes propiedades de los núcleos celulares en las imágenes FNA. Estas características incluyen:\n",
        "- Radio (radius)\n",
        "- Textura (texture)\n",
        "- Perímetro (perimeter)\n",
        "- Área (area)\n",
        "- Suavidad (smoothness)\n",
        "- Compacidad (compactness)\n",
        "- Concavidad (concavity)\n",
        "- Puntos cóncavos (concave points)\n",
        "- Simetría (symmetry)\n",
        "- Dimensión fractal (fractal dimension)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "El objetivo de este análisis es desarrollar un modelo de clasificación utilizando árboles de decisión que pueda ayudar a determinar si un tumor es benigno (B) o maligno (M) en función de las características del núcleo celular. Utilizaremos variables como el radio medio del tumor, la textura media, el perímetro medio, el área media, entre otras, para realizar estas predicciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnN4hkaMDQxm"
      },
      "outputs": [],
      "source": [
        "# Cargando modulos necesarios\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz, plot_tree\n",
        "from sklearn.metrics import accuracy_score\n",
        "from IPython.display import Image\n",
        "import pydotplus\n",
        "from io import StringIO\n",
        "from sklearn.impute import SimpleImputer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHIhh1_aDo5h"
      },
      "source": [
        "# Lectura y visualización de información general de dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4MvO1ZcD7oQ",
        "outputId": "9c09de6a-b986-45f3-99c8-7905143e6bb9"
      },
      "outputs": [],
      "source": [
        "# Cargar el conjunto de datos Breast Cancer Wisconsin\n",
        "data = pd.read_csv(\"breast-cancer-wisconsin-data_data.csv\")\n",
        "\n",
        "# Mostrar información general del conjunto de datos\n",
        "print(\"Información general del conjunto de datos:\")\n",
        "print(data.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHW6MxwfExnJ",
        "outputId": "579339e4-92dc-4973-8860-1b54db116103"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "NuwSWlM_EWOd",
        "outputId": "8775a91e-76bb-4024-ff29-add8c9016431"
      },
      "outputs": [],
      "source": [
        "data.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ODnIAPJFPVB"
      },
      "source": [
        "# Preparación de datos para entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwHWheCIF6XZ"
      },
      "outputs": [],
      "source": [
        "# Definir la variable objetivo y las características (variables predictoras)\n",
        "y = data[\"diagnosis\"]\n",
        "X = data.drop([\"diagnosis\", \"id\", \"Unnamed: 32\"], axis=1)  # Eliminar columnas no deseadas\n",
        "\n",
        "# Imputar los valores faltantes con la media de cada columna\n",
        "imputer = SimpleImputer(strategy=\"mean\")\n",
        "X_imputed = imputer.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "xZIVoC4kGFXB",
        "outputId": "40587b79-93ae-47eb-d82b-9f493809002e"
      },
      "outputs": [],
      "source": [
        "# Table con características\n",
        "X.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdqEJAfvGWBa",
        "outputId": "f4ee6369-b862-401e-80d4-3e597363886f"
      },
      "outputs": [],
      "source": [
        "# Variable objetivo\n",
        "y.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Db9DhqcHGzex"
      },
      "source": [
        "## Separación del dataset en sets de entrenamiento y prueba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnTMWrN-Fx2r"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, random_state=27)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjZ5ayUBHEsB"
      },
      "source": [
        "## Entrenamiento del árbol de decisión"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mw2ST8Wg5YRK",
        "outputId": "72217328-7cc4-4d45-9c75-b48704dc6aab"
      },
      "outputs": [],
      "source": [
        "# Crear el clasificador del árbol de decisión\n",
        "arbol_c = DecisionTreeClassifier()\n",
        "arbol_c.fit(X_train, y_train)\n",
        "# Mostrar el árbol de clasificación\n",
        "plt.figure(figsize=(20, 20))\n",
        "plot_tree(arbol_c, filled=True, feature_names=X.columns, fontsize=10)\n",
        "plt.show()\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "predichos = arbol_c.predict(X_test)\n",
        "\n",
        "# Calcular la tasa de aciertos\n",
        "tasa_aciertos = accuracy_score(y_test, predichos)\n",
        "print(\"Aciertos:\", tasa_aciertos)\n",
        "print(\"Aciertos %:\", tasa_aciertos*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1N7TXKkHrhS",
        "outputId": "ce46dcf3-a52e-4ee9-8a93-dd9ab8b9a46b"
      },
      "outputs": [],
      "source": [
        "# Crear un DataFrame para mostrar la comparación entre los valores reales y predichos\n",
        "comparacion_df = pd.DataFrame({'Valor Real': y_test.values[:10], 'Valor Predicho': predichos[:10]})\n",
        "\n",
        "print(\"\\nTabla de comparación entre Valor Real y Valor Predicho:\")\n",
        "print(comparacion_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWg7t0QZNPtw"
      },
      "source": [
        "## **Ajuste de Hiperparámetros**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6ptFVx1Ir_Q"
      },
      "source": [
        "## Modificando la profundidad del árbol (max_depth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 753
        },
        "id": "Q51MtNDYIrFi",
        "outputId": "a594c248-61a1-4b11-df15-1f52b78c0ff7"
      },
      "outputs": [],
      "source": [
        "# Crear un árbol de clasificación con una profundidad máxima de 3 para visualización\n",
        "arbol_c2 = DecisionTreeClassifier(max_depth=3) # Modificable\n",
        "arbol_c2.fit(X_train, y_train)\n",
        "\n",
        "predichos2 = arbol_c2.predict(X_test)\n",
        "\n",
        "# Visualizar el árbol de clasificación más legible\n",
        "dot_data = StringIO()\n",
        "export_graphviz(arbol_c2, out_file=dot_data,\n",
        "                filled=True, rounded=True,\n",
        "                special_characters=True, feature_names=X.columns, class_names=['B', 'M'])\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
        "Image(graph.create_png())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbvelaA5JMJh",
        "outputId": "729b898e-d9af-4e5a-e975-befea28254bd"
      },
      "outputs": [],
      "source": [
        "# Calcular la tasa de aciertos del árbol podado en el conjunto de prueba\n",
        "tasa_acierto2 = arbol_c2.score(X_test, y_test)\n",
        "print(\"Tasa de acierto del árbol con profundidad máxima 3:\", tasa_acierto2)\n",
        "print(\"Tasa de acierto del árbol con profundidad máxima 3 %:\", tasa_acierto2*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHIvCYzgJgXJ",
        "outputId": "428367ee-17eb-4eea-88aa-e29323a680d1"
      },
      "outputs": [],
      "source": [
        "# Crear un DataFrame para mostrar la comparación entre los valores reales y predichos\n",
        "comparacion_df = pd.DataFrame({'Valor Real': y_test.values[:10], 'Valor Predicho': predichos2[:10]})\n",
        "\n",
        "print(\"\\nTabla de comparación entre Valor Real y Valor Predicho:\")\n",
        "print(comparacion_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZAqZy84I3AZ"
      },
      "source": [
        "## Mejorando resultados mediante modificación de poda\n",
        "\n",
        "El CCP alpha (Cost Complexity Pruning alpha) es un parámetro utilizado en la poda (pruning) basada en la complejidad de costo en los árboles de decisión. La poda es una técnica utilizada para reducir la complejidad y el sobreajuste de los árboles de decisión al eliminar las ramas que no aportan un beneficio significativo en términos de precisión de predicción.\n",
        "\n",
        "El CCP alpha controla el equilibrio entre el ajuste del árbol a los datos de entrenamiento y la simplicidad del árbol resultante. Un valor mayor de CCP alpha conduce a una poda más agresiva, lo que significa que se eliminarán más nodos y ramas del árbol. Por otro lado, un valor menor de CCP alpha conservará más nodos y ramas, lo que resultará en un árbol más complejo y ajustado a los datos de entrenamiento.\n",
        "\n",
        "En general, el CCP alpha suele estar en el rango de 0 a 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "RVue8GYsatgn",
        "outputId": "a57fc43e-37a4-4818-af94-ebb6d24b0af9"
      },
      "outputs": [],
      "source": [
        "arbol_c3 = DecisionTreeClassifier(ccp_alpha=0.02) # Modificar con un valor entre 0 y 1\n",
        "arbol_c3.fit(X_train, y_train)\n",
        "\n",
        "predichos3 = arbol_c3.predict(X_test)\n",
        "\n",
        "# Visualizar el árbol de clasificación podado\n",
        "dot_data = StringIO()\n",
        "export_graphviz(arbol_c3, out_file=dot_data,\n",
        "                filled=True, rounded=True,\n",
        "                special_characters=True, feature_names=X.columns, class_names=['B', 'M'])\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
        "Image(graph.create_png())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuKUKupba52g",
        "outputId": "45bb3bd2-3994-4611-ecb1-6d560de13f73"
      },
      "outputs": [],
      "source": [
        "# Calcular la tasa de aciertos del árbol podado en el conjunto de prueba\n",
        "tasa_acierto3 = arbol_c3.score(X_test, y_test)\n",
        "print(\"Tasa de acierto del árbol podado:\", tasa_acierto3)\n",
        "print(\"Tasa de acierto del árbol podado:\", tasa_acierto3*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cD_dmyPia7B3",
        "outputId": "e4137566-a73d-4b1d-daf5-4df07031d690"
      },
      "outputs": [],
      "source": [
        "# Crear un DataFrame para mostrar la comparación entre los valores reales y predichos\n",
        "comparacion_df = pd.DataFrame({'Valor Real': y_test.values[:10], 'Valor Predicho': predichos3[:10]})\n",
        "\n",
        "print(\"\\nTabla de comparación entre Valor Real y Valor Predicho:\")\n",
        "print(comparacion_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_kTi9fIbVBB"
      },
      "source": [
        "## **Optimizando hipermarámetros**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 929
        },
        "id": "fhkv6eTCHgZZ",
        "outputId": "47d4565b-3f2f-43a7-96ab-24d914c6fa72"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Realizar la poda del árbol utilizando el parámetro ccp_alpha\n",
        "alfas = arbol_c.cost_complexity_pruning_path(X_train, y_train)\n",
        "ccp_alphas = alfas.ccp_alphas\n",
        "\n",
        "# Construir todos los árboles posibles con los diferentes valores de ccp_alpha\n",
        "clfs = []\n",
        "for ccp_alpha in ccp_alphas:\n",
        "    clf = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
        "    clf.fit(X_train, y_train)\n",
        "    clfs.append(clf)\n",
        "\n",
        "# Calcular las tasas de aciertos y el número de nodos para cada árbol\n",
        "test_scores = [clf.score(X_test, y_test) for clf in clfs]\n",
        "node_counts = [clf.tree_.node_count for clf in clfs]\n",
        "\n",
        "# Encontrar el valor ccp_alpha que maximiza la tasa de aciertos\n",
        "optimal_alpha = ccp_alphas[np.argmax(test_scores)]\n",
        "\n",
        "# Crear un árbol de clasificación con el valor óptimo de ccp_alpha\n",
        "arbol_c4 = DecisionTreeClassifier(ccp_alpha=optimal_alpha)\n",
        "arbol_c4.fit(X_train, y_train)\n",
        "\n",
        "predichos3 = arbol_c4.predict(X_test)\n",
        "\n",
        "print(\"optimal alpha:\", optimal_alpha)\n",
        "\n",
        "# Visualizar el árbol de clasificación podado\n",
        "dot_data = StringIO()\n",
        "export_graphviz(arbol_c4, out_file=dot_data,\n",
        "                filled=True, rounded=True,\n",
        "                special_characters=True, feature_names=X.columns, class_names=['B', 'M'])\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
        "Image(graph.create_png())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jg3RgJsSJW_Y",
        "outputId": "d0b6c241-0c3c-4da3-8553-ad675069a31a"
      },
      "outputs": [],
      "source": [
        "# Calcular la tasa de aciertos del árbol podado en el conjunto de prueba\n",
        "tasa_acierto4 = arbol_c4.score(X_test, y_test)\n",
        "print(\"Tasa de acierto del árbol podado:\", tasa_acierto4)\n",
        "print(\"Tasa de acierto del árbol podado:\", tasa_acierto4*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HcTNIVBKL5C"
      },
      "source": [
        "# **Regresion**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwTGyidBKO7y",
        "outputId": "c93871fd-619d-460f-8d0d-06bda3742223"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor, export_graphviz, plot_tree\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.impute import SimpleImputer\n",
        "from IPython.display import Image\n",
        "import pydotplus\n",
        "from io import StringIO\n",
        "\n",
        "# Cargar el conjunto de datos Breast Cancer Wisconsin\n",
        "data = pd.read_csv(\"breast-cancer-wisconsin-data_data.csv\")\n",
        "\n",
        "# Mostrar información general del conjunto de datos\n",
        "print(\"Información general del conjunto de datos:\")\n",
        "print(data.info())\n",
        "\n",
        "# Utilizar \"perimeter_mean\" como variable objetivo para la regresión\n",
        "y = data[\"perimeter_mean\"]\n",
        "X = data.drop([\"diagnosis\", \"id\", \"Unnamed: 32\", \"perimeter_mean\"], axis=1)  # Eliminar columnas no deseadas\n",
        "\n",
        "# Imputar los valores faltantes con la media de cada columna\n",
        "imputer = SimpleImputer(strategy=\"mean\")\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Separar el conjunto de datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, random_state=27)\n",
        "\n",
        "# Crear el regresor del árbol de regresión\n",
        "arbol_regresion = DecisionTreeRegressor(max_depth=3)\n",
        "\n",
        "# Entrenar el modelo\n",
        "arbol_regresion.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "predicciones = arbol_regresion.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAzl_6Bqqm8D"
      },
      "outputs": [],
      "source": [
        "# Calcular el error cuadrado medio (MSE)\n",
        "mse = mean_squared_error(y_test, predicciones)\n",
        "print(\"Error cuadrado medio (MSE):\", mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "hEclUgy0QmXH",
        "outputId": "b6949434-c9ad-4283-865b-0b0ef7a5db35"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "import pydotplus\n",
        "from IPython.display import Image\n",
        "\n",
        "# Visualizar el árbol de regresión\n",
        "dot_data = export_graphviz(arbol_regresion, out_file=None,\n",
        "                           filled=True, rounded=True, special_characters=True,\n",
        "                           feature_names=X.columns)\n",
        "graph = pydotplus.graph_from_dot_data(dot_data)\n",
        "Image(graph.create_png())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDJEFIheqrdU"
      },
      "source": [
        "# Validación cruzada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UppwN4bQpgU",
        "outputId": "50a49688-7cf3-4113-c32e-514e5736cfb5"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Crear el regresor del árbol de regresión con la profundidad máxima deseada\n",
        "arbol_regresion = DecisionTreeRegressor(max_depth=3)\n",
        "\n",
        "# Realizar validación cruzada\n",
        "scores = cross_val_score(arbol_regresion, X_imputed, y, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Convertir los scores negativos a MSE positivos\n",
        "mse_scores = -scores\n",
        "\n",
        "# Calcular el promedio de los MSE\n",
        "mean_mse = mse_scores.mean()\n",
        "\n",
        "print(\"Promedio del Error cuadrado medio (MSE) en validación cruzada:\", mean_mse)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
